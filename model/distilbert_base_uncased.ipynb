{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "2TsY_PnaPSiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAx6ZoGe-kgN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DefaultDataCollator\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Tu3MSLlQ23D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/model'\n",
        "import os\n",
        "os.listdir(folder_path)"
      ],
      "metadata": {
        "id": "yFKuyA3yRU-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset"
      ],
      "metadata": {
        "id": "G8X3w4g6Oqjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_dir):\n",
        "    with open(data_dir, 'r', encoding = 'utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data"
      ],
      "metadata": {
        "id": "uJ2MMBDz-yH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert file json to Dataframe"
      ],
      "metadata": {
        "id": "rOGyJybcjajN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = read_data( folder_path + '/Dataset/UIT-ViQuAD.json')\n",
        "contexts = []\n",
        "questions = []\n",
        "answers = []\n",
        "ids = []\n",
        "for data in dataset['data']:\n",
        "    for para in data['paragraphs']:\n",
        "        context = para['context']\n",
        "        for qa in para['qas']:\n",
        "            question = qa['question']\n",
        "            for answer in qa['answers']:\n",
        "                contexts.append(context)\n",
        "                questions.append(question)\n",
        "                answers.append({'answer_start': [answer['answer_start']], 'text': [answer['text']]})\n",
        "                ids.append(qa['id'])\n",
        "icqa = [ids, contexts, questions, answers] "
      ],
      "metadata": {
        "id": "llpd4O1T_Uh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(ids, contexts, questions, answers)),\n",
        "               columns =['ids', 'contexts', 'questions', 'answers'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Ni-IJnvmPJvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate train/test"
      ],
      "metadata": {
        "id": "uitbe7fJ6LRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=df.sample(frac=0.8,random_state=200)\n",
        "test=df.drop(train.index)"
      ],
      "metadata": {
        "id": "ZwQRArvAP7b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function pre process-tokenizer"
      ],
      "metadata": {
        "id": "nujxd1866RWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    # examples = train[input_ids]\n",
        "    questions = [q.strip() for q in examples[\"questions\"]]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"contexts\"],\n",
        "        max_length=512,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "kkaaAS2lenPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "import datasets\n",
        "\n",
        "table = pa.Table.from_pydict(train)\n",
        "rows = table.to_pydict()\n",
        "dataset_train = datasets.Dataset.from_dict(rows)\n",
        "\n",
        "table2 = pa.Table.from_pydict(test)\n",
        "rows2 = table.to_pydict()\n",
        "dataset_eval = datasets.Dataset.from_dict(rows2)"
      ],
      "metadata": {
        "id": "JhV-ADECs2Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_squad_eval = dataset_eval.map(preprocess_function, batched=True)\n",
        "tokenized_squad_train = dataset_train.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "Rr0Sm1wc3j9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DefaultDataCollator()\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "5gYsZZJ43Bhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_squad_train)"
      ],
      "metadata": {
        "id": "2JdIXHfZKF5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_squad_train[0])"
      ],
      "metadata": {
        "id": "fDsIwgKNKRrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H9L2FQDaKhO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"transformer_qa\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=24,\n",
        "    per_device_eval_batch_size=24,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_squad_train,\n",
        "    eval_dataset=tokenized_squad_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "MgQr65JD3Gwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = '''Giai đoạn năm 1955-1976, Phạm Văn Đồng nắm giữ chức vụ gì?'''\n",
        "context = '''Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).'''"
      ],
      "metadata": {
        "id": "tki-mze6ifyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\", model=\"/content/drive/MyDrive/model/transformer_qa/checkpoint-500\")\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "id": "sLv6Qm-kjnCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}